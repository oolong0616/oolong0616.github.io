---
layout:     post  
title:      1、概述  
subtitle:   笔记：Spark 官方文档(更新至2.4.3)  
date:       2018-05-20  
author:     岑晨  
header-img: 
catalog: true  
tags:  
    - spark   
    
    - 笔记
---

# 安全

Spark默认关闭了安全管理

# Spark 安装配置 

Spark使用Hadoop基础库用于支持HDFS及Yarn，可以两种模式设置：

- 直接下载Hadoop对应版本

- 下载"Hadoop Free"版本，并配置

  - 路径：conf/spark-env.sh
  - 内容

  ```bash
  # Hadoop路径已经配置，直接使用环境变量
  export SPARK_DIST_CLASSPATH=$(hadoop classpath)
  
  # 导入Hadoop路径
  export SPARK_DIST_CLASSPATH=$(/path/to/hadoop/bin/hadoop classpath)
  
  # 传递Hadoop configuration路径
  export SPARK_DIST_CLASSPATH=$(hadoop --config /path/to/configs classpath)
  ```

  

安装配置：

- 下载Spark(Pre-built)版本  

- 安装对应版本JDK

- 解压文件夹  

# 示例   

运行Spark自带示例：
```bash
.$SPARK_HOME/bin/pyspark 
```
> 参照文档  
> 				[ApacheCN](https://github.com/oolong0616/spark-doc-zh.git)     
> 				[Spark官方文档](http://spark.apache.org/docs/2.2.0/)      
