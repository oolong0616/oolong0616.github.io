---
layout:     post  
title:      笔记：Spark 官方文档(2.2.0)  
subtitle:   概述  
date:       2019-05-20  
author:     岑晨  
header-img: 
catalog: true  
tags:  
    - spark  
    - 笔记
---  

## 配置   
通过增加Spark的类路径下载“Pre-bulit”版本运行Spark。  
- 路径：    
```bash
cd $SPARK_HOME/conf/spark-env.sh
```
- 内容： 
```bash
export export SPARK_DIST_CLASSPATH=$(XXXXXX/bin/hadoop classpath)
```

## 示例   
Python（各版本路径不同）：   
```bash
./bin/spark-submit  /userDir/spark/spark-2.4.1-bin-hadoop2.6/examples/src/main/python/pi.py 10 
```
## 部署   
- 独立部署
- Apache Mesos  
- Yarn   
> 参照文档  
    ApacheCN：https://github.com/oolong0616/spark-doc-zh.git  
    Spark官方：http://spark.apache.org/docs/2.2.0/    


